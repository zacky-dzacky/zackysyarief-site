---
title: '[Draft] Working With vector and cosine similiraty using Sqlite + Ollama'
date: '2025-11-14'
tags: ['AI','RAG']
draft: true
summary: 'When we design RAG Architecture, the most important part is how we translate our exisiting data into vectors using embedding query. Let say we have a collection of journals and we want those collections to be context in addtion to our prompt, we need select the relev ...'
---

## Background
When we design RAG Architecture, the most important part is how we transform our exisiting data into vectors using embedding process. Let say we have a collection of journals and we want those collections to be context in addtion to our prompt, we need select the relevant data within those journals. But what if the relevant data included into several documents, 

## Type of similarity
+ Cosine similarity
+ Euclidean Similarity
+ Jaccard Similarity
+ Dot Product

## Cosine Similarity Formula

## Hands On 
- <h3>Transform text  into vector</h3>

When we talk about search mechanism, there are two kind of those, which are Lexical and semantic search. Lexical similarity means that when we search a text, we make sure all the text that we'are looking is exactly same with exisitng data. for example:
```
# Given text
`Today is monday`
`Monday is funtastic day`
`Elephant is the biggest living animal on land`

# Given query
`monday`

# So when we search text monday, the given text will be part of the result
`Today is monday`
`Monday is funtastic day`
```

Different with Lexical, semantic search give us the capability to go beyonds text similarity, we can search by meaning similirity. As we know that `book` is similir like `textbook`. So, that's why we vector, as vector data give us the flexibility to count the distance/similarity between text. For example:

```
# Given 

```
There is to kind of First thing first, we need to make sure all the data transformed into vector. As we know that for semantice
+ Saved vector to SQLITE
+ Query embedding to vector
+ Calculate cosine distance
+ Result

## Conclusion

## Reference
+ [IBM - What is cosine similarity?](https://www.ibm.com/think/topics/cosine-similarity)
